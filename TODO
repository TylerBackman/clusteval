* Fix Errors

I'm getting the following error in the second artificial data set with K = 3:

Number of Clusters: 2
2: In FUN(c(3L, 2L, 1L)[[3L]], ...) :
  Error in clustomit_boot: more cluster centers than distinct data points.
Number of Rows in x: 1

The issue is caused by the 'with_replacement' option. Let n be the true sample size, and
let m be the number of unique observations kept. If n = 5 and K = 3, it is quite possible
that m = 1 or 2. This can cause m < 2, which causes the above error.

Now we need to figure out how to overcome this. One possibility is to resort back to
the regular bootstrap and warn that for n << p, we can have an issue in that there is
multicollinearity, in that the same observation can be used multiple times.

However, I'm starting to question my original reasoning for using the 'with_replacement'
option. If there are enough bootstrap samples used, repeating the same observation, say
5 times, can yield a lower intrinsic dimension; however, as B, the number of bootstrap
reps, increases, this should not matter. If any thing, having problematic observations
can yield bimodal/multimodal Jaccard scores, which can be useful for diagnostic purposes.
TODO: Add this note to the paper.


With that in mind, I am going to set the default to 'with_replacement = TRUE'.

There is still an issue though. Consider for example K = 3 with the following number of
observations in each cluster:
n_1 = 98
n_2 = 1
n_3 = 1

Suppose that we sample with replacement from the 100 observations, which omits the
singleton observation from cluster 2. Now, if we omit cluster 1, we only have
a single observation from cluster 3. Hence, we try to cluster a single observation
with K - 1 = 2 clusters. This is the exact cause of the above error in the unit test.

One possible fix is a stratified bootstrapping approach (i.e. resample with replacement
from each of the observed clusters), but I am not convinced that this mixes up the
data enough to really test how good the clustering is. Perhaps, I should add this as
an option and see how well it works.

Another fix is to borrow something like Hennig's method. With his method, he looks for
overlap between a cluster and the bootstrapped sample. If there is no overlap, he
ignores this bootstrap rep. So, his reported Jaccard average only averages over the
bootstrap reps that had overlap. Although this seems a bit ad hoc, this might provide
a reasonable model to follow in how to deal with the above problem case.


* ClustOmit SimDesign for Testing

J = Jaccard
CR = Completely Random with equal a priori probabilities
COS = Cluster Omission Stability statistic

** TODO For each SimDesign, manually calculate:
    E_CR[COS] = 1/(M-1) (?)
    V_CR[COS] = ?
** TODO For each simulation, check that the average simulated COS score is very close to the E_CR[COS]
    By close, I mean with 3 standard deviations

* Clustering Wrappers
** Determine the common items that each clustering algorithm should return

Obviously, the cluster labels should be returned. But there should be some conditional items that should be returned, such
as cluster membership posterior probabilities if available (fuzzy labels). Obviously, there will be the actual object returned
by the clustering algorithm. Because this can be quite large, this should only be stored if the user sets the flag to do so.
By default, this should be stored, so that out of the box, things are handled as expected. But this should be turned off
because the storage can be quite overwhelming for a large number of clustering algorithms and/or large data sets.

See the 'caret' package for a lookup table of available features for each clustering algorithm.

** TODO Create the frontend function for clustering
** TODO Create kmeans wrapper
** TODO Add kmeans unit test with iris data set for a variety of values of K
For a fixed RNG seed, the cluster labels should be the same using the wrapper and the original method. 
** TODO Create diana wrapper
** TODO Add diana unit test with iris data set for a variety of values of K
For a fixed RNG seed, the cluster labels should be the same using the wrapper and the original method. 
** TODO Create PAM wrapper
** TODO Add PAM unit test with iris data set for a variety of values of K
For a fixed RNG seed, the cluster labels should be the same using the wrapper and the original method. 


** TODO Create mclust wrapper
** TODO Add mclust unit test with iris data set for a variety of values of K
For a fixed RNG seed, the cluster labels should be the same using the wrapper and the original method. 

** TODO Create lookup table for common elements

* Next Actions
** TODO Determine SimConfig for Multivariate Gamma data
** TODO Implement Multivariate Gamma function to generate data
** TODO Create graphical outputs for each of FOM, clusterboot, and clustomit for each family of distributions:
  - Bivariate Uniform
  - Multivariate Normal
  - Multivariate Student's t
  - Multivariate Gamma
** TODO Add 'clusteval' package to PNNL's version of the CRAN repository :pnnl:
** TODO Add package level documentation to clustomit                   :pnnl:
** TODO Add data sets for each data set in the package:                :pnnl:
  - St. Jude
  - SRBCT
** TODO Add documentation for each data set in clustomit:              :pnnl:
  - St. Jude
  - SRBCT
  - For an example, see:
    - https://github.com/hadley/devtools/wiki/docs-function
** TODO Add error checking for positive sample sizes to:               :pnnl:
  - Bivariate Uniform
  - Multivariate Normal
  - Multivariate Student's t
  - Multivariate Gamma
** TODO Add unit test to check the errors for each of:                 :pnnl:
  - Bivariate Uniform
  - Multivariate Normal
  - Multivariate Student's t
  - Multivariate Gamma
** TODO Add unit test to verify proper output of:                      :pnnl:
  - Bivariate Uniform
  - Multivariate Normal
  - Multivariate Student's t
  - Multivariate Gamma
** TODO Finish Unit Test #2 for consensus clustering                   :pnnl:
* Maybe/Someday
** Write Rcpp version of similarity functions
** Implement improved version of FOM
** Create a MapReduce or GPU version of major clustering algorithms
** Add hpc = T/F option. If TRUE, use a better method than the built-in method.  
